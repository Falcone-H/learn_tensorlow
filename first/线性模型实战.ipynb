{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy  as np\n",
    "\n",
    "\n",
    "data = [] # 保存样本集的列表\n",
    "for i in range(100):\n",
    "    x = np.random.uniform(-10., 10.) # 随机采样输入 x\n",
    "    eps = np.random.normal(0., 0.01) # 采样高斯噪声\n",
    "    y = 1.477 * x + 0.089 + eps # 得到模型输出\n",
    "    data.append([x, y]) # 保存样本点\n",
    "data = np.array(data) # 转换为2D Numpy数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004151078948789324\n"
     ]
    }
   ],
   "source": [
    "print(eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算误差\n",
    "def mse(b, w, points):\n",
    "    totalError = 0\n",
    "    for i in range(0, len(points)): \n",
    "        x = points[i, 0] # 获取i号点的输入x\n",
    "        y = points[i, 1] # 获取i号点的输出y\n",
    "        totalError += (y - (w * x + b)) ** 2 # 计算误差，并累加\n",
    "    return totalError / float(len(points))  # 将累加的误差求平均，得到均方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算梯度\n",
    "def step_gradient(b_current, w_current, points, lr):\n",
    "    b_gradient = 0\n",
    "    w_gradient = 0\n",
    "    M = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        # 误差函数对b的导数\n",
    "        b_gradient += (2/M) * ((w_current * x + b_current) - y)\n",
    "        # 误差函数对w的导数\n",
    "        w_gradient += (2/M) * x * ((w_current * x + b_current) - y)\n",
    "    # 根据梯度下降算法更新 w', b', 其中lr为学习率\n",
    "    new_b = b_current - (lr * b_gradient)\n",
    "    new_w = w_current - (lr * w_gradient)\n",
    "    return [new_b, new_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度更新\n",
    "def gradient_descent(points, starting_b, starting_w, lr, num_iterations):\n",
    "    b = starting_b\n",
    "    w = starting_w\n",
    "    # 根据梯度下降算法更新多次\n",
    "    for step in range(num_iterations):\n",
    "        b, w = step_gradient(b, w, np.array(points), lr)\n",
    "        loss = mse(b, w, points) # 计算当前的均方差，用于监控训练进度\n",
    "        if step%50 == 0: # 打印误差和实时的w, b 值\n",
    "            print(f\"iteration:{step}, loss:{loss}, w:{w}, b{b}\")\n",
    "    return [b, w]  # 返回最后一次的w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主训练函数\n",
    "def main():\n",
    "    # 加载训练集数据，这些数据是通过真实模型添加观测误差采样得到的\n",
    "    lr = 0.01 # 学习率\n",
    "    initial_b = 0 # 初始化b\n",
    "    initial_w = 0 # 初始化w\n",
    "    num_iterations = 1000\n",
    "    # 训练优化1000次，返回最优 w*, b* 和训练loss的下降过程\n",
    "    [b, w] = gradient_descent(data, initial_b, initial_w, lr, num_iterations)\n",
    "    loss = mse(b, w, data) # 计算最优数值解w, b上的均方差\n",
    "    print(f'Final_loss:{loss}, w:{w}, b:{b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0, loss:8.324909730150774, w:0.9763694560043762, b0.01808096884041486\n",
      "iteration:50, loss:0.0006655704135862034, w:1.477553902277715, b0.06697030494724514\n",
      "iteration:100, loss:0.00019594194645215811, w:1.4772992911148601, b0.0817730657056694\n",
      "iteration:150, loss:0.00013244416262746898, w:1.47720566876936, b0.08721614670235554\n",
      "iteration:200, loss:0.00012385871938283327, w:1.4771712431633548, b0.0892176065124538\n",
      "iteration:250, loss:0.00012269789405528438, w:1.4771585846218231, b0.08995355759859\n",
      "iteration:300, loss:0.00012254094054657384, w:1.477153929985571, b0.09022417207630892\n",
      "iteration:350, loss:0.00012251971909033057, w:1.4771522184425323, b0.09032367895513638\n",
      "iteration:400, loss:0.00012251684976801065, w:1.4771515890959162, b0.0903602683461306\n",
      "iteration:450, loss:0.00012251646181110325, w:1.4771513576806647, b0.09037372252687785\n",
      "iteration:500, loss:0.00012251640935601258, w:1.4771512725876217, b0.0903786697253597\n",
      "iteration:550, loss:0.00012251640226363988, w:1.477151241298301, b0.09038048884562265\n",
      "iteration:600, loss:0.00012251640130468545, w:1.4771512297929943, b0.09038115774915322\n",
      "iteration:650, loss:0.00012251640117502877, w:1.4771512255624106, b0.09038140370976523\n",
      "iteration:700, loss:0.00012251640115749855, w:1.4771512240067948, b0.09038149415124132\n",
      "iteration:750, loss:0.00012251640115512692, w:1.4771512234347837, b0.0903815274072189\n",
      "iteration:800, loss:0.00012251640115480648, w:1.477151223224451, b0.09038153963567971\n",
      "iteration:850, loss:0.00012251640115476422, w:1.4771512231471102, b0.09038154413217223\n",
      "iteration:900, loss:0.00012251640115475593, w:1.4771512231186714, b0.09038154578556468\n",
      "iteration:950, loss:0.00012251640115475718, w:1.4771512231082145, b0.09038154639352886\n",
      "Final_loss:0.0001225164011547558, w:1.4771512231044144, b:0.09038154661445416\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
